{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "400c8a10-6f02-472d-852f-b4a0bd50acb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "17fed803-18c5-4ae2-af38-f1e84954c9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class websiteData:\n",
    "    def __init__(self, str_reviews=[], str_reviews_title=[], str_reviews_date=[], full_star = [], empty_star = [],\n",
    "                 reviews_hrefs=[], reviews_text_links=[], reviews_full_links=[], site_headers={}, rev_api_link = '', reviews_rating_data = [],\n",
    "                 website_main_link='', reviews_title_links=[], reviews_content_links=[], website_name = '', api_total_elements = '',\n",
    "                 reviews_and__links_on_them={}, website_link='', reviews_posting_date_links=[], number_of_stars = [], review_status = []):\n",
    "\n",
    "        self.revTxt = str_reviews\n",
    "        self.revTitle = str_reviews_title\n",
    "        self.revDate = str_reviews_date\n",
    "        self.htmlClasses = {\n",
    "            \"revTxt\": reviews_text_links,\n",
    "            \"revFull\": reviews_full_links,\n",
    "            \"revTitle\": reviews_title_links,\n",
    "            \"revContent\": reviews_content_links,\n",
    "            \"revDate\": reviews_posting_date_links\n",
    "        }\n",
    "        self.links = {\n",
    "            \"allWebsite\": website_main_link,\n",
    "            \"websiteUrl\": website_link,\n",
    "            \"revLinks\": reviews_hrefs,\n",
    "            \"api\": rev_api_link\n",
    "        }\n",
    "        self.api = {\n",
    "            \"totalElem\": api_total_elements\n",
    "        }\n",
    "        self.revPlusOtherData = reviews_and__links_on_them\n",
    "        self.headers = site_headers\n",
    "        self.name = website_name\n",
    "        self.rating = {\n",
    "            \"star\": full_star,\n",
    "            \"emptyStar\": empty_star,\n",
    "            \"ratingNum\": number_of_stars,\n",
    "            \"revStatus\": review_status\n",
    "        }\n",
    "        self.revRating = reviews_rating_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e08882f8-fca8-465b-ad67-cdc0fdbd287d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_getting(url, text_class, need_href, w):    #w -- website (class)\n",
    "    r = requests.get(url, headers=w.headers)\n",
    "    soup = BeautifulSoup(r.text, 'lxml')\n",
    "    reviews_text = soup.find_all(class_=w.htmlClasses[text_class][0])\n",
    "    for q in range(1, len(w.htmlClasses[text_class])):\n",
    "        for i, rev in enumerate(reviews_text):\n",
    "            reviews_text[i] = rev.find(class_=w.htmlClasses[text_class][q])\n",
    "            #print(reviews_text[i])\n",
    "\n",
    "    c = 0\n",
    "    reviews_clean = [[], []]\n",
    "    reviews_rating = [[], []]\n",
    "\n",
    "    if need_href:\n",
    "        reviews_hrefs = [[], []]\n",
    "        for review in reviews_text:\n",
    "            if review != None:\n",
    "                if w.revRating[c] > 3:\n",
    "                    co = 1\n",
    "                else:\n",
    "                    co = 0\n",
    "                reviews_clean[co].append(review.text)\n",
    "                reviews_rating[co].append(w.revRating[c])\n",
    "                try:\n",
    "                    reviews_hrefs[co].append(w.links[allWebsite] + review.get(\"href\"))\n",
    "                except Exception:\n",
    "                    reviews_hrefs[co].append(\"None\")\n",
    "                c += 1\n",
    "        return reviews_clean, reviews_rating, reviews_hrefs\n",
    "\n",
    "    else:\n",
    "        for review in reviews_text:\n",
    "            if review != None:\n",
    "                if w.revRating[c] > 3:\n",
    "                    co = 1\n",
    "                else:\n",
    "                    co = 0\n",
    "                reviews_clean[co].append(review.text)\n",
    "                reviews_rating[co].append(w.revRating[c])\n",
    "                c += 1\n",
    "        return reviews_clean, reviews_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f5903160-f6d4-4679-98cd-34da0a68c5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(reviews):\n",
    "    review_converted = []\n",
    "    for review in reviews:\n",
    "        for i in review:\n",
    "            map(str, i)\n",
    "        review = ''.join(review)\n",
    "        review_converted.append(review)\n",
    "    return review_converted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "aa3fb47e-3b65-455f-a8f0-8ed594d21f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rating_getting(url, w):\n",
    "    r = requests.get(url, headers=w.headers)\n",
    "    soup = BeautifulSoup(r.text, 'lxml')\n",
    "    reviews_text = soup.find_all(class_=w.rating[star])\n",
    "    for q in range(1, len(w.rating[star]) - 1):\n",
    "        for i, rev in enumerate(reviews_text):\n",
    "            reviews_text[i] = rev.find(class_=w.rating[star][q])\n",
    "\n",
    "    reviews_rating = []\n",
    "    for rev in reviews_text:\n",
    "        q = rev.find_all(class_=w.rating[star][-1])\n",
    "        #print(q)\n",
    "        if len(q) != 0:\n",
    "            reviews_rating.append(len(q))\n",
    "    return reviews_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8d9a7422-3213-43f1-b2bc-a6774d7e91fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def parsing(url, status, path, text_class, w):    # w -- website (class)\n",
    "#     print('--- Parsing in process... ---')\n",
    "#     delays = [1, 2, 1.5]\n",
    "#     #delays = [11, 12, 13, 11.5, 12.5, 13.5, 11.2, 12.3, 11.8]\n",
    "#     time.sleep(np.random.choice(delays))\n",
    "#     addData = []\n",
    "#     for _ in range(1):\n",
    "#         for classI in text_class:\n",
    "#             received_data = data_getting(url, classI, False, w)\n",
    "#             if received_data == []:\n",
    "#                 break\n",
    "#         # Eсли папок с классами не существует, программа их создаст\n",
    "#         # if not os.path.exists(path + fr'{w.name}\\{status}'):\n",
    "#         #     os.makedirs(path + fr'{w.name}\\{status}')\n",
    "#             converted_data = convert(received_data)\n",
    "#             dataSize = len(converted_data)\n",
    "#             #for i, review in enumerate(converted_data):\n",
    "#             for dta in converted_data:\n",
    "#\n",
    "#\n",
    "#                 time.sleep(np.random.choice(delays))\n",
    "#     with open(path + f'{w.name}_{status}.json', 'w', encoding='utf-8') as file:\n",
    "#         json.dump(addData, file, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "83920daf-5278-4404-bcc3-76288fd2f87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data receiving\n",
    "def review_other_data(titles, data, w):\n",
    "    pos, neg = \"Negative\", \"Positive\"\n",
    "    links_to_the_reviews = {\n",
    "        pos: {},\n",
    "        neg: {}\n",
    "    }\n",
    "\n",
    "    for e in range(2):\n",
    "        if e == 1:\n",
    "            st = neg\n",
    "        else:\n",
    "            st = pos\n",
    "\n",
    "        for i in range(len(titles[e])):\n",
    "            links_to_the_reviews[st][titles[e][i]] = {}\n",
    "            for j in range(len(data)):\n",
    "                if data[j] == []:\n",
    "                    links_to_the_reviews[st][titles[e][i]][dataTypes[j]] = 'None'\n",
    "                else:\n",
    "                    links_to_the_reviews[st][titles[e][i]][dataTypes[j]] = data[j][e][i]\n",
    "\n",
    "    if not os.path.exists(r'result\\from_html'):\n",
    "        os.makedirs(r'result\\from_html')\n",
    "    with open(fr'result\\from_html\\revData_{w.name}.json', 'w', encoding='utf-8') as file:\n",
    "        json.dump(links_to_the_reviews, file, indent=4, ensure_ascii=False)\n",
    "    #return links_to_the_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c75f67f6-c3d3-4fd8-9790-e1391d9e5f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# var/val initialization\n",
    "\n",
    "revTxt, revFull, revTitle, revContent, revDate = \"revTxt\", \"revFull\", \"revTitle\", \"revContent\", \"revDate\"\n",
    "allWebsite, revLinks, websiteUrl, api, totalElem = \"allWebsite\", \"revLinks\", \"websiteUrl\", \"api\", \"totalElem\"\n",
    "star, emptyStar, ratingNum, revStatus = 'star', 'emptyStar', 'ratingNum', 'revStatus'\n",
    "\n",
    "sravni_ru, rustore = websiteData(), websiteData()\n",
    "\n",
    "dataTypes = ['Title', 'Link', 'Date', 'Rating']\n",
    "\n",
    "rev_websites = {\n",
    "    sravni_ru: r\"https://www.sravni.ru/bank/tinkoff-bank/otzyvy/\",\n",
    "    rustore: r\"https://apps.rustore.ru/app/com.idamob.tinkoff.android/reviews\"\n",
    "}\n",
    "\n",
    "urles_api = {\n",
    "    sravni_ru: r'https://www.sravni.ru/proxy-reviews/reviews/?filterBy=withRates&fingerPrint=eab9ea9d6cdaf03fcbbff091af5c0195&isClient=false&locationRoute=&newIds=true&orderBy=byDate&pageIndex=1&pageSize=10&reviewObjectId=5bb4f769245bc22a520a6353&reviewObjectType=banks&specificProductId=&withVotes=true',\n",
    "    rustore: r'https://backapi.rustore.ru/comment/comment?packageName=com.idamob.tinkoff.android&sortBy=NEW_FIRST&pageSize=100&pageNumber=0'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4ccfaa0d-2c55-45f1-a4a7-b09b51b83f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sravni.ru init\n",
    "\n",
    "sravni_ru.links[websiteUrl] = rev_websites[sravni_ru]\n",
    "sravni_ru.links[allWebsite] = r'https://www.sravni.ru/'\n",
    "\n",
    "sravni_ru.htmlClasses[revTxt] = ['review-card_link__b9zg3']\n",
    "sravni_ru.htmlClasses[revFull] = ['review-card_wrapper__gnPSK common_blockWrapper__Fw5ZV']\n",
    "sravni_ru.htmlClasses[revTitle] = ['review-card_title__zYdxx articleTypography_article-h3__wuxLw']\n",
    "sravni_ru.htmlClasses[revContent] = ['review-card_text__jTUSq articleTypography_article-comment__Px4n0 h-mt-8 h-mb-8 review-card_text__in-list__DsDRg']\n",
    "sravni_ru.htmlClasses[revDate] = ['h-mb-20 _1n8o0h2 _vea58f _1ivat6c _pbfp49', '_1n8o0h2 _vea58f _1ivat6c', '_1n8o0h2 _vea58f']\n",
    "\n",
    "sravni_ru.rating[star] = ['h-mb-20 _1n8o0h2 _vea58f _1ivat6c _pbfp49', '_n6sdlh _akgnn3 _8136q1 _1xowbbl _18zu2v3 _g18kgu shape-round']\n",
    "\n",
    "\n",
    "# for num in range(1, 2482):\n",
    "#     q, sravni_ru.links[revLinks] = load_data(sravni_ru.links[websiteUrl] + f\"&pageIndex={num}\", sravni_ru.htmlClasses[revTxt], sravni_ru.links[allWebsite], True)\n",
    "#\n",
    "#     for i in q:\n",
    "#         sravni_ru.revBad.append(i)\n",
    "\n",
    "sravni_ru.name = \"sravni.ru\"\n",
    "\n",
    "sravni_ru.headers = {\n",
    "    \"Accept\": \"*/*\",\n",
    "    \"User-Agent\": r\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 YaBrowser/24.1.0.0 Safari/537.36\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e59222dc-f391-4264-a62a-bb0b3e4e7d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rustore.ru init\n",
    "\n",
    "rustore.links[websiteUrl] = rev_websites[rustore]\n",
    "rustore.links[allWebsite] = 'https://apps.rustore.ru/'\n",
    "rustore.links[api] = 'https://backapi.rustore.ru/comment/comment?packageName=com.idamob.tinkoff.android&sortBy=NEW_FIRST&pageSize=1000&pageNumber='\n",
    "rustore.api[totalElem] = 'totalElements'\n",
    "\n",
    "rustore.htmlClasses[revTxt] = ['ReviewItems_comment__W6IzJ']\n",
    "rustore.htmlClasses[revFull] = ['ReviewItems_wrapperItem__edebG']\n",
    "rustore.htmlClasses[revTitle] = ['None']\n",
    "rustore.htmlClasses[revDate] = ['ReviewItems_date__XJhw_']\n",
    "rustore.htmlClasses[revContent] = ['ReviewItems_comment__W6IzJ']\n",
    "\n",
    "rustore.rating[star] = ['']\n",
    "\n",
    "rustore.name = \"rustore.ru\"\n",
    "\n",
    "rustore.headers = {\n",
    "    \"Accept\": \"*/*\",\n",
    "    \"User-Agent\": r\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 YaBrowser/24.1.0.0 Safari/537.36\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0f19e2f6-9614-43fb-b6ab-8f4955d3771e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_getting_api_rustore(w=rustore):\n",
    "    pos, neg, neut = \"Positive\", \"Negative\", \"Neutral\"\n",
    "    links_to_the_reviews_json = {\n",
    "        pos: [],\n",
    "        neg: []\n",
    "    }\n",
    "\n",
    "    links_to_the_reviews_csv = {\n",
    "        pos: [[], [], []],\n",
    "        neg: [[], [], []],\n",
    "        neut: [[], [], []]\n",
    "    }\n",
    "    pageNum = 0\n",
    "    flag = False\n",
    "    while True:\n",
    "        url = w.links[api] + str(pageNum)\n",
    "        r = requests.get(url, headers=w.headers)\n",
    "        webJson = r.json()\n",
    "        for q1, q2 in webJson.items():\n",
    "            if q1 == 'body':\n",
    "                for item1, item2 in q2.items():\n",
    "                    if item1 == 'content':\n",
    "                        for rev in item2:\n",
    "                            q = {'Text': '', 'Rate': 0, 'Date': ''}\n",
    "                            for wh, cont in rev.items():\n",
    "\n",
    "                                if wh == 'appRating':\n",
    "                                    if cont < 3:\n",
    "                                        csv_st = neg\n",
    "                                    elif cont > 3:\n",
    "                                        csv_st = pos\n",
    "                                    else:\n",
    "                                        csv_st = neut\n",
    "                                    q['Rate'] = cont\n",
    "                                    links_to_the_reviews_csv[csv_st][1].append(cont)\n",
    "\n",
    "                                elif wh == 'commentDate':\n",
    "                                    f = cont.split()\n",
    "                                    q['Date'] = f[0]\n",
    "                                    links_to_the_reviews_csv[csv_st][2].append(f[0])\n",
    "\n",
    "                                elif wh == 'commentText':\n",
    "                                    q['Text'] = cont\n",
    "                                    links_to_the_reviews_csv[csv_st][0].append(cont)\n",
    "\n",
    "                            if q['Rate'] < 3:\n",
    "                                links_to_the_reviews_json[neg].append(q)\n",
    "                            elif q['Rate'] > 3:\n",
    "                                links_to_the_reviews_json[pos].append(q)\n",
    "\n",
    "                    if item1 == 'totalElements':\n",
    "                         if item2 == 0:\n",
    "                             flag = True\n",
    "                             break\n",
    "                if flag:\n",
    "                    break\n",
    "        if flag:\n",
    "            break\n",
    "\n",
    "        pageNum += 1\n",
    "    dataset_creating(links_to_the_reviews_json, links_to_the_reviews_csv, w, pos, neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e1b920ec-e752-4f12-9af8-31cfcb54a6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_getting_api_sravni_ru(w=sravni_ru):\n",
    "    pos, neg, neut = \"Positive\", \"Negative\", \"Neutral\"\n",
    "    links_to_the_reviews_json = {\n",
    "        pos: [],\n",
    "        neg: []\n",
    "    }\n",
    "\n",
    "    links_to_the_reviews_csv = {\n",
    "        pos: [[], [], []],\n",
    "        neg: [[], [], []],\n",
    "        neut: [[], [], []]\n",
    "    }\n",
    "    pageNum = 0\n",
    "    while True:\n",
    "        url = fr'https://www.sravni.ru/proxy-reviews/reviews/?filterBy=withRates&fingerPrint=eab9ea9d6cdaf03fcbbff091af5c0195&isClient=false&locationRoute=&newIds=true&orderBy=byDate&pageIndex={str(pageNum)}&pageSize=1000&reviewObjectId=5bb4f769245bc22a520a6353&reviewObjectType=banks&specificProductId=&withVotes=true'\n",
    "        r = requests.get(url, headers=w.headers)\n",
    "        webJson = r.json()\n",
    "        if len(webJson['items']) == 0:\n",
    "            break\n",
    "        for rev in webJson['items']:\n",
    "            q = {'Text': '', 'Rate': 0, 'Date': ''}\n",
    "            for wh, cont in rev.items():\n",
    "                if wh == 'rating':\n",
    "                    if cont < 3:\n",
    "                        csv_st = neg\n",
    "                    elif cont > 3:\n",
    "                        csv_st = pos\n",
    "                    else:\n",
    "                        csv_st = neut\n",
    "                    q['Rate'] = cont\n",
    "                    links_to_the_reviews_csv[csv_st][1].append(cont)\n",
    "\n",
    "                elif wh == 'date':\n",
    "                    f = cont.split()\n",
    "                    q['Date'] = f[0]\n",
    "                    links_to_the_reviews_csv[csv_st][2].append(f[0])\n",
    "                elif wh == 'title':\n",
    "                    q['Text'] = cont\n",
    "                elif wh == 'text':\n",
    "                    q['Text'] += (' ' + cont)\n",
    "                    links_to_the_reviews_csv[csv_st][0].append(q['Text'])\n",
    "\n",
    "            if q['Rate'] < 3:\n",
    "                links_to_the_reviews_json[neg].append(q)\n",
    "            elif q['Rate'] > 3:\n",
    "                links_to_the_reviews_json[pos].append(q)\n",
    "\n",
    "        pageNum += 1\n",
    "    dataset_creating(links_to_the_reviews_json, links_to_the_reviews_csv, w, pos, neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "24f2a8c0-970a-4aef-bc73-747b383b4774",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_creating(links_to_the_reviews_json, links_to_the_reviews_csv, w, pos, neg):\n",
    "    print('--- Dataset creating... ---')\n",
    "    # запись в json файл\n",
    "    if not os.path.exists(fr'result\\api\\{w.name}\\json'):\n",
    "        os.makedirs(fr'result\\api\\{w.name}\\json')\n",
    "    if not os.path.exists(fr'result\\api\\{w.name}\\csv'):\n",
    "        os.makedirs(fr'result\\api\\{w.name}\\csv')\n",
    "\n",
    "    with open(fr'result\\api\\{w.name}\\json\\revData_{w.name}.json', 'w', encoding='utf-8') as file:\n",
    "        json.dump(links_to_the_reviews_json, file, indent=4, ensure_ascii=False)\n",
    "\n",
    "    # запись в csv файл\n",
    "    with open(fr'result\\api\\{w.name}\\csv\\revData_{w.name}.csv', 'w', encoding='utf-8') as file_csv, open(fr'result\\api\\{w.name}\\csv\\revData_{w.name}_pos.csv', 'w', encoding='utf-8') as file_csv_pos, open(fr'result\\api\\{w.name}\\csv\\revData_{w.name}_neg.csv', 'w', encoding='utf-8') as file_csv_neg:\n",
    "        q = csv.writer(file_csv)\n",
    "        q_pos = csv.writer(file_csv_pos)\n",
    "        q_neg = csv.writer(file_csv_neg)\n",
    "\n",
    "        q.writerow(\n",
    "            (\n",
    "                \"Status\",\n",
    "                \"Text\",\n",
    "                \"Rating\",\n",
    "                \"Date\"\n",
    "            )\n",
    "        )\n",
    "        q_pos.writerow(\n",
    "            (\n",
    "                \"Text\",\n",
    "                \"Rating\",\n",
    "                \"Date\"\n",
    "            )\n",
    "        )\n",
    "        q_neg.writerow(\n",
    "            (\n",
    "                \"Text\",\n",
    "                \"Rating\",\n",
    "                \"Date\"\n",
    "            )\n",
    "        )\n",
    "        for i in range(len(links_to_the_reviews_csv[pos][0])):\n",
    "            q.writerow(\n",
    "                (\n",
    "                    pos,\n",
    "                    links_to_the_reviews_csv[pos][0][i],\n",
    "                    links_to_the_reviews_csv[pos][1][i],\n",
    "                    links_to_the_reviews_csv[pos][2][i]\n",
    "                )\n",
    "            )\n",
    "            q_pos.writerow(\n",
    "                (\n",
    "                    links_to_the_reviews_csv[pos][0][i],\n",
    "                    links_to_the_reviews_csv[pos][1][i],\n",
    "                    links_to_the_reviews_csv[pos][2][i]\n",
    "                )\n",
    "            )\n",
    "        for i in range(len(links_to_the_reviews_csv[neg][0])):\n",
    "            q.writerow(\n",
    "                (\n",
    "                    neg,\n",
    "                    links_to_the_reviews_csv[neg][0][i],\n",
    "                    links_to_the_reviews_csv[neg][1][i],\n",
    "                    links_to_the_reviews_csv[neg][2][i]\n",
    "                )\n",
    "            )\n",
    "            q_neg.writerow(\n",
    "                (\n",
    "                    links_to_the_reviews_csv[neg][0][i],\n",
    "                    links_to_the_reviews_csv[neg][1][i],\n",
    "                    links_to_the_reviews_csv[neg][2][i]\n",
    "                )\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b4e10ffc-f258-4b3a-a224-a1aa7e695600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ in the functions... ------\n"
     ]
    }
   ],
   "source": [
    "print('------ in the functions... ------')\n",
    "def solve():\n",
    "    data_getting_api_rustore()\n",
    "    # sravni_ru.revRating = rating_getting(sravni_ru.links[websiteUrl], sravni_ru)\n",
    "    #\n",
    "    # q, w, e = data_getting(sravni_ru.links[websiteUrl], revTxt, True, sravni_ru)\n",
    "    # sravni_ru.revTxt = [convert(q[0]), convert(q[1])]\n",
    "    # sravni_ru.rating[star] = w\n",
    "    # sravni_ru.links[revLinks] = [convert(e[0]), convert(e[1])]\n",
    "    #\n",
    "    # q, w = data_getting(sravni_ru.links[websiteUrl], revTitle, False, sravni_ru)\n",
    "    # sravni_ru.revTitle = [convert(q[0]), convert(q[1])]\n",
    "    #\n",
    "    # q, w = data_getting(sravni_ru.links[websiteUrl], revDate, False, sravni_ru)\n",
    "    # sravni_ru.revDate = [convert(q[0]), convert(q[1])]\n",
    "    #\n",
    "    # review_other_data(sravni_ru.revTxt, [sravni_ru.revTitle, sravni_ru.links[revLinks], sravni_ru.revDate, sravni_ru.rating[star]], sravni_ru)\n",
    "\n",
    "\n",
    "    # rustore.revRating = rating_getting(rustore.links[websiteUrl], rustore)\n",
    "    #\n",
    "    # q, w, e = data_getting(rustore.links[websiteUrl], revContent, True, rustore)\n",
    "    # rustore.revTxt = [convert(q[0]), convert(q[1])]\n",
    "    # rustore.rating[star] = w\n",
    "    # rustore.links[revLinks] = [convert(e[0]), convert(e[1])]\n",
    "    #\n",
    "    #\n",
    "    # q, w = data_getting(rustore.links[websiteUrl], revDate, False, rustore)\n",
    "    # rustore.revDate = [convert(q[0]), convert(q[1])]\n",
    "    #review_other_data(rustore.revTxt, [[], rustore.links[revLinks], [], []], rustore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "725d17aa-438b-42cf-8e4d-7cc8bfe8e9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# func activation\n",
    "\n",
    "# for title, link in sravni_ru.revPlusLink.items():\n",
    "#     rep = [',', ' ', '-', ' ']\n",
    "#     for item in rep:\n",
    "#         if item in title:\n",
    "#             title = title.replace(item, \"_\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6cff8b1a-861c-4c37-8cc4-d612c374f917",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = ''\n",
    "# urles = ''\n",
    "# statuses = ['positive', 'negative']\n",
    "# delays = [1, 2, 1.4]\n",
    "# #delays = [15, 20, 13, 18, 12.5, 13.5, 25, 12.3, 23]\n",
    "#\n",
    "# for website, url in rev_websites.items():\n",
    "#     for status in statuses:\n",
    "#         try:\n",
    "#             parsing(url, status, path, [revTxt], website)\n",
    "#             print(f\"--- Group '{status}': success ---\")\n",
    "#             time.sleep(np.random.choice(delays))\n",
    "#\n",
    "#         except AttributeError:\n",
    "#             print(f\"---! Бан получен: {url}, {status} !---\")\n",
    "#             break\n",
    "# # Блок else выполняется тогда, когда внутренний цикл НЕ прерывается\n",
    "# # если внутренний цикл прерывается, то прерывается и внешний\n",
    "#     else:\n",
    "#         print(f\"--- Website '{website.name}': success ---\")\n",
    "#         continue\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bb51c54a-ce3c-4175-b4e8-1ebd68da790b",
   "metadata": {},
   "outputs": [],
   "source": [
    "solve()\n",
    "\n",
    "\n",
    "# any ideas\n",
    "# мини доп. функция: добавить окно, где можно будет по кластеру найти нужные отзывы: будет храниться тайтл отзыва и ссылка на него"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
